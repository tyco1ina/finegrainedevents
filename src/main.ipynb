{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                  Version\n",
      "------------------------ ----------\n",
      "allennlp                 2.10.1\n",
      "altgraph                 0.17.2\n",
      "annotated-types          0.6.0\n",
      "anyio                    4.2.0\n",
      "appnope                  0.1.4\n",
      "asttokens                2.4.1\n",
      "backoff                  2.2.1\n",
      "base58                   2.1.1\n",
      "blis                     0.7.11\n",
      "boto3                    1.34.39\n",
      "botocore                 1.34.39\n",
      "cached-path              1.1.6\n",
      "cachetools               5.3.2\n",
      "catalogue                2.0.10\n",
      "certifi                  2024.2.2\n",
      "charset-normalizer       3.3.2\n",
      "chromadb                 0.3.26\n",
      "click                    8.1.7\n",
      "clickhouse-connect       0.7.0\n",
      "coloredlogs              15.0.1\n",
      "comm                     0.2.1\n",
      "commonmark               0.9.1\n",
      "cymem                    2.0.8\n",
      "debugpy                  1.8.1\n",
      "decorator                5.1.1\n",
      "dill                     0.3.8\n",
      "docker-pycreds           0.4.0\n",
      "duckdb                   0.9.2\n",
      "emoji                    2.10.1\n",
      "exceptiongroup           1.2.0\n",
      "executing                2.0.1\n",
      "fairscale                0.4.6\n",
      "fastapi                  0.109.2\n",
      "filelock                 3.7.1\n",
      "flatbuffers              23.5.26\n",
      "fsspec                   2024.2.0\n",
      "future                   0.18.2\n",
      "gitdb                    4.0.11\n",
      "GitPython                3.1.41\n",
      "google-api-core          2.17.0\n",
      "google-auth              2.27.0\n",
      "google-cloud-core        2.4.1\n",
      "google-cloud-storage     2.14.0\n",
      "google-crc32c            1.5.0\n",
      "google-resumable-media   2.7.0\n",
      "googleapis-common-protos 1.62.0\n",
      "h11                      0.14.0\n",
      "h5py                     3.10.0\n",
      "hnswlib                  0.8.0\n",
      "httptools                0.6.1\n",
      "huggingface-hub          0.20.3\n",
      "humanfriendly            10.0\n",
      "idna                     3.6\n",
      "importlib-metadata       7.0.1\n",
      "iniconfig                2.0.0\n",
      "ipykernel                6.29.2\n",
      "ipython                  8.18.1\n",
      "jedi                     0.19.1\n",
      "Jinja2                   3.1.3\n",
      "jmespath                 1.0.1\n",
      "joblib                   1.3.2\n",
      "jsonnet                  0.20.0\n",
      "jupyter_client           8.6.0\n",
      "jupyter_core             5.7.1\n",
      "langcodes                3.3.0\n",
      "lmdb                     1.4.1\n",
      "lz4                      4.3.3\n",
      "macholib                 1.15.2\n",
      "MarkupSafe               2.1.5\n",
      "matplotlib-inline        0.1.6\n",
      "monotonic                1.6\n",
      "more-itertools           10.2.0\n",
      "mpmath                   1.3.0\n",
      "murmurhash               1.0.10\n",
      "mypy-extensions          1.0.0\n",
      "nest-asyncio             1.6.0\n",
      "networkx                 3.2.1\n",
      "nltk                     3.8.1\n",
      "numpy                    1.26.4\n",
      "onnxruntime              1.17.0\n",
      "overrides                7.7.0\n",
      "packaging                23.2\n",
      "pandas                   2.2.0\n",
      "parso                    0.8.3\n",
      "pathlib_abc              0.1.1\n",
      "pathtools                0.1.2\n",
      "pathy                    0.11.0\n",
      "pexpect                  4.9.0\n",
      "pillow                   10.2.0\n",
      "pip                      21.2.4\n",
      "platformdirs             4.2.0\n",
      "pluggy                   1.4.0\n",
      "posthog                  3.4.0\n",
      "preshed                  3.0.9\n",
      "promise                  2.3\n",
      "prompt-toolkit           3.0.43\n",
      "protobuf                 3.20.3\n",
      "psutil                   5.9.8\n",
      "ptyprocess               0.7.0\n",
      "pulsar-client            3.4.0\n",
      "pure-eval                0.2.2\n",
      "pyasn1                   0.5.1\n",
      "pyasn1-modules           0.3.0\n",
      "pydantic                 1.10.11\n",
      "pydantic_core            2.16.2\n",
      "Pygments                 2.17.2\n",
      "pytest                   8.0.0\n",
      "python-dateutil          2.8.2\n",
      "python-dotenv            1.0.1\n",
      "pytz                     2024.1\n",
      "PyYAML                   6.0.1\n",
      "pyzmq                    25.1.2\n",
      "regex                    2023.12.25\n",
      "requests                 2.31.0\n",
      "rich                     12.6.0\n",
      "rsa                      4.9\n",
      "s3transfer               0.10.0\n",
      "sacremoses               0.1.1\n",
      "safetensors              0.4.2\n",
      "scikit-learn             1.4.0\n",
      "scipy                    1.12.0\n",
      "sentencepiece            0.1.99\n",
      "sentry-sdk               1.40.3\n",
      "setproctitle             1.3.3\n",
      "setuptools               58.0.4\n",
      "shortuuid                1.0.11\n",
      "six                      1.15.0\n",
      "smart-open               6.4.0\n",
      "smmap                    5.0.1\n",
      "sniffio                  1.3.0\n",
      "spacy                    3.3.3\n",
      "spacy-legacy             3.0.12\n",
      "spacy-loggers            1.0.5\n",
      "srsly                    2.4.8\n",
      "stack-data               0.6.3\n",
      "stanza                   1.7.0\n",
      "starlette                0.36.3\n",
      "sympy                    1.12\n",
      "tensorboardX             2.6.2.2\n",
      "termcolor                1.1.0\n",
      "thinc                    8.0.17\n",
      "threadpoolctl            3.2.0\n",
      "tokenizers               0.15.1\n",
      "toml                     0.10.2\n",
      "tomli                    2.0.1\n",
      "torch                    1.12.1\n",
      "torchvision              0.13.1\n",
      "tornado                  6.4\n",
      "tqdm                     4.66.2\n",
      "traitlets                5.14.1\n",
      "transformers             4.37.2\n",
      "typer                    0.4.2\n",
      "typing_extensions        4.9.0\n",
      "typing-inspect           0.8.0\n",
      "tzdata                   2023.4\n",
      "urllib3                  1.26.18\n",
      "uvicorn                  0.27.1\n",
      "uvloop                   0.19.0\n",
      "wandb                    0.12.21\n",
      "wasabi                   0.10.1\n",
      "watchfiles               0.21.0\n",
      "wcwidth                  0.2.13\n",
      "websockets               12.0\n",
      "wheel                    0.37.0\n",
      "zipp                     3.17.0\n",
      "zstandard                0.22.0\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip3 list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip3 install allennlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip3 install numpy\n",
    "! pip3 install pandas\n",
    "\n",
    "! pip3 install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip3 install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip3 install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip3 install stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='pypi.org', port=443): Read timed out. (read timeout=15)\")': /simple/transformers/\u001b[0m\n",
      "\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='pypi.org', port=443): Read timed out. (read timeout=15)\")': /simple/transformers/\u001b[0m\n",
      "Collecting transformers<4.21\n",
      "  Using cached transformers-4.20.1-py3-none-any.whl (4.4 MB)\n",
      "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
      "  Using cached tokenizers-0.12.1-cp39-cp39-macosx_10_11_x86_64.whl (3.6 MB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/tiberiuscolina/Library/Python/3.9/lib/python/site-packages (from transformers<4.21) (6.0.1)\n",
      "Requirement already satisfied: filelock in /Users/tiberiuscolina/Library/Python/3.9/lib/python/site-packages (from transformers<4.21) (3.7.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/tiberiuscolina/Library/Python/3.9/lib/python/site-packages (from transformers<4.21) (2023.12.25)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/tiberiuscolina/Library/Python/3.9/lib/python/site-packages (from transformers<4.21) (23.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/tiberiuscolina/Library/Python/3.9/lib/python/site-packages (from transformers<4.21) (4.66.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/tiberiuscolina/Library/Python/3.9/lib/python/site-packages (from transformers<4.21) (1.26.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /Users/tiberiuscolina/Library/Python/3.9/lib/python/site-packages (from transformers<4.21) (0.20.3)\n",
      "Requirement already satisfied: requests in /Users/tiberiuscolina/Library/Python/3.9/lib/python/site-packages (from transformers<4.21) (2.31.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/tiberiuscolina/Library/Python/3.9/lib/python/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers<4.21) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/tiberiuscolina/Library/Python/3.9/lib/python/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers<4.21) (4.9.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/tiberiuscolina/Library/Python/3.9/lib/python/site-packages (from requests->transformers<4.21) (3.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/tiberiuscolina/Library/Python/3.9/lib/python/site-packages (from requests->transformers<4.21) (2024.2.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/tiberiuscolina/Library/Python/3.9/lib/python/site-packages (from requests->transformers<4.21) (1.26.18)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/tiberiuscolina/Library/Python/3.9/lib/python/site-packages (from requests->transformers<4.21) (3.3.2)\n",
      "Installing collected packages: tokenizers, transformers\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.15.1\n",
      "    Uninstalling tokenizers-0.15.1:\n",
      "      Successfully uninstalled tokenizers-0.15.1\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.37.2\n",
      "    Uninstalling transformers-4.37.2:\n",
      "      Successfully uninstalled transformers-4.37.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "chromadb 0.3.26 requires tokenizers>=0.13.2, but you have tokenizers 0.12.1 which is incompatible.\u001b[0m\n",
      "Successfully installed tokenizers-0.12.1 transformers-4.20.1\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip3 install 'transformers<4.21' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting tokenizers==0.11.1\n",
      "  Downloading tokenizers-0.11.1-cp39-cp39-macosx_10_11_x86_64.whl (3.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.7 MB 2.0 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: tokenizers\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.12.1\n",
      "    Uninstalling tokenizers-0.12.1:\n",
      "      Successfully uninstalled tokenizers-0.12.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "chromadb 0.3.26 requires tokenizers>=0.13.2, but you have tokenizers 0.11.1 which is incompatible.\u001b[0m\n",
      "Successfully installed tokenizers-0.11.1\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip3 install tokenizers==0.11.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip3 install typing-inspect==0.8.0 typing_extensions==4.5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip3 install pydantic -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip3 install pydantic==1.10.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 15:57:14 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOT HERE 1\n",
      "GOT HERE 2\n",
      "GOT HERE 3\n",
      "GOT HERE 4\n",
      "GOT HERE 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.7.0.json: 370kB [00:00, 102MB/s]                     \n",
      "2024-02-12 15:57:15 INFO: Loading these models for language: en (English):\n",
      "===============================\n",
      "| Processor | Package         |\n",
      "-------------------------------\n",
      "| tokenize  | combined        |\n",
      "| mwt       | combined        |\n",
      "| pos       | combined_charlm |\n",
      "===============================\n",
      "\n",
      "2024-02-12 15:57:15 INFO: Using device: cpu\n",
      "2024-02-12 15:57:15 INFO: Loading: tokenize\n",
      "2024-02-12 15:57:15 INFO: Loading: mwt\n",
      "2024-02-12 15:57:15 INFO: Loading: pos\n",
      "2024-02-12 15:57:15 INFO: Done loading processors!\n",
      "2024-02-12 15:57:15 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.7.0.json: 370kB [00:00, 47.1MB/s]                    \n",
      "2024-02-12 15:57:16 INFO: Loading these models for language: en (English):\n",
      "=================================\n",
      "| Processor | Package           |\n",
      "---------------------------------\n",
      "| tokenize  | combined          |\n",
      "| mwt       | combined          |\n",
      "| pos       | combined_charlm   |\n",
      "| lemma     | combined_nocharlm |\n",
      "| depparse  | combined_charlm   |\n",
      "=================================\n",
      "\n",
      "2024-02-12 15:57:16 INFO: Using device: cpu\n",
      "2024-02-12 15:57:16 INFO: Loading: tokenize\n",
      "2024-02-12 15:57:16 INFO: Loading: mwt\n",
      "2024-02-12 15:57:16 INFO: Loading: pos\n",
      "2024-02-12 15:57:17 INFO: Loading: lemma\n",
      "2024-02-12 15:57:17 INFO: Loading: depparse\n",
      "2024-02-12 15:57:17 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOT HERE 6\n",
      "GOT HERE 7\n",
      "GOT HERE 8\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(\"GOT HERE 1\")\n",
    "import pandas as pd\n",
    "print(\"GOT HERE 2\")\n",
    "import json\n",
    "print(\"GOT HERE 3\")\n",
    "import nltk\n",
    "print(\"GOT HERE 4\")\n",
    "from data_utils import BuildPOS\n",
    "print(\"GOT HERE 5\")\n",
    "from process_text import BuildVocab, TextToSentences\n",
    "print(\"GOT HERE 6\")\n",
    "import torch.utils.data as data \n",
    "print(\"GOT HERE 7\")\n",
    "import time\n",
    "print(\"GOT HERE 8\")\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print(epoch, loss):\n",
    "    print('Epoch {} completed with loss {:.4f}'.format(epoch + 1, loss * (0.9 ** epoch)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data.json') as f:\n",
    "    dataset = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary built in 0.9552 sec, with size: 6326\n"
     ]
    }
   ],
   "source": [
    "vocab = BuildVocab()\n",
    "start = time.time()\n",
    "for i in range(len(dataset)):\n",
    "    text = TextToSentences(dataset[i]['news'].lower())\n",
    "    vocab.addText(text)\n",
    "print('Vocabulary built in {:.4f} sec, with size: {}'.format(time.time() - start, vocab.n_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS built in 0.0008 sec, with size: 16\n"
     ]
    }
   ],
   "source": [
    "pos = BuildPOS()\n",
    "start = time.time()\n",
    "for i in range(len(dataset)):\n",
    "    p = dataset[i]['pos']\n",
    "    pos.addPOS(p)\n",
    "print('POS built in {:.4f} sec, with size: {}'.format(time.time() - start, pos.n_pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StockPredictionDataset(data.Dataset):\n",
    "    def __init__(self, dataset, vocab, pos):\n",
    "        self.data = dataset\n",
    "        self.vocab = vocab\n",
    "        self.pos = pos\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        news_, pos_, stock_ = self.data[i]['news'], self.data[i]['pos'], self.data[i]['stock']\n",
    "        news_ = torch.Tensor(self.process_sent(news_)).long()\n",
    "        pos_ = torch.Tensor(self.process_pos(news_, pos_)).long()\n",
    "        stock_ = np.array(stock_)\n",
    "        y = int(np.sum((stock_[-1,:6] - stock_[-2,:6])) > 0) if len(stock_) >= 2 else 1\n",
    "        stock_ = torch.Tensor(stock_)\n",
    "        return news_, pos_, stock_, y\n",
    "    \n",
    "    def process_sent(self, sent):\n",
    "        tokens = nltk.word_tokenize(sent.lower())\n",
    "        out = []\n",
    "        out.append(self.vocab.word2index['<SOS>'])\n",
    "        out.extend([self.vocab.word2index[token] for token in tokens if token in self.vocab.word2index])\n",
    "        out.append(self.vocab.word2index['<EOS>'])\n",
    "        return out\n",
    "    \n",
    "    def process_pos(self, sent, pos):\n",
    "        out = [self.pos.pos2index['<SOS>']]\n",
    "        out.extend([self.pos.pos2index[token] for token in pos])\n",
    "        if len(sent) <= (len(pos) + 1):\n",
    "            pos = pos[:len(sent) - 2] \n",
    "        out.extend([self.pos.pos2index[pos[-1]] for _ in range(len(sent) - len(pos) - 2) ])\n",
    "        out.append(self.pos.pos2index['<EOS>'])\n",
    "        return out\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(data):\n",
    "    def merge(sequences, is_token):\n",
    "        lengths = [len(seq) for seq in sequences]\n",
    "        if is_token:\n",
    "            padded_seqs = torch.zeros(len(sequences), max(lengths)).long()\n",
    "        else:\n",
    "            padded_seqs = torch.zeros(len(sequences), max(lengths), 120)\n",
    "        for i, seq in enumerate(sequences):\n",
    "            end = lengths[i]\n",
    "            if end == 0:\n",
    "                continue\n",
    "            padded_seqs[i,:end] = seq[:]\n",
    "        return padded_seqs, lengths\n",
    "              \n",
    "    news, pos, stock, y = [], [], [], []\n",
    "    for i, (news_i, pos_i, stock_i, y_i) in enumerate(data):\n",
    "        news.append(news_i)\n",
    "        pos.append(pos_i)\n",
    "        stock.append(stock_i)\n",
    "        y.append(y_i)\n",
    "    news.sort(key = lambda x: len(x), reverse=True)\n",
    "    pos.sort(key = lambda x: len(x), reverse=True)\n",
    "    stock.sort(key = lambda x: len(x), reverse=True)\n",
    "    news, news_lengths = merge(news, True)\n",
    "    pos, _ = merge(pos, True)\n",
    "    stock, stock_lengths = merge(stock, False)\n",
    "    y = torch.Tensor(y)\n",
    "    return news, pos, stock, y, news_lengths, stock_lengths\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = StockPredictionDataset(dataset, vocab, pos)\n",
    "dataloader = torch.utils.data.DataLoader(dataset = dataset, batch_size=64, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import MSSPM\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_emb_dim = 256\n",
    "hidden_dim = 256\n",
    "vocab_size = vocab.n_words\n",
    "event_size = pos.n_pos\n",
    "num_heads = 4\n",
    "num_epochs = 10\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SSPM(vocab_size, word_emb_dim, hidden_dim, event_size, num_heads)\n",
    "model.cuda()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-2)\n",
    "\n",
    "for e in range(num_epochs):\n",
    "    for i, (news, pos, stock, y, sent_lengths, stock_lengths) in enumerate(dataloader):\n",
    "        bsize = len(news)\n",
    "        for i in range(bsize):\n",
    "            if sent_lengths[i] == 0:\n",
    "                sent_lengths[i] += 1\n",
    "            elif stock_lengths[i] == 0:\n",
    "                stock_lengths[i] += 1\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        \"\"\"\n",
    "        news = news.cuda()\n",
    "        pos = pos.cuda()\n",
    "        stock = stock.cuda()\n",
    "        y = y.cuda().view(-1, 1)\n",
    "        probs = model(news, pos, stock, sent_lengths, stock_lengths)\n",
    "        loss = criterion(probs, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    pretty_print(e, loss.item())   \n",
    "    \"\"\"   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_emb_dim = 256\n",
    "hidden_dim = 256\n",
    "vocab_size = vocab.n_words\n",
    "event_size = pos.n_pos\n",
    "num_heads = 4\n",
    "num_epochs = 10\n",
    "eta = 0.5\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Attention hidden dimension is not divisible by the number of attention heads",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[39m=\u001b[39m MSSPM(vocab_size, word_emb_dim, hidden_dim, event_size, num_heads)\n\u001b[1;32m      2\u001b[0m model\u001b[39m.\u001b[39mcuda()\n\u001b[1;32m      3\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mSGD(model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m1e-2\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/ComputerStuff/School/nlpfinancial/finegrainedevents/src/model.py:254\u001b[0m, in \u001b[0;36mMSSPM.__init__\u001b[0;34m(self, hidden_dim, sent_encoder_layers, stock_encoder_layers, num_heads, dropout, mode, **kwargs)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, hidden_dim, sent_encoder_layers \u001b[39m=\u001b[39m \u001b[39m3\u001b[39m, stock_encoder_layers \u001b[39m=\u001b[39m \u001b[39m3\u001b[39m, num_heads \u001b[39m=\u001b[39m \u001b[39m4\u001b[39m, \\\n\u001b[1;32m    253\u001b[0m              dropout \u001b[39m=\u001b[39m \u001b[39m0.2\u001b[39m, mode \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 254\u001b[0m     \u001b[39massert\u001b[39;00m (hidden_dim \u001b[39m*\u001b[39m \u001b[39m2\u001b[39m) \u001b[39m%\u001b[39m num_heads \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAttention hidden dimension is not divisible by the number of attention heads\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    255\u001b[0m     \u001b[39massert\u001b[39;00m mode \u001b[39min\u001b[39;00m (\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m), \u001b[39m'\u001b[39m\u001b[39mCurrent mode not supported\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    256\u001b[0m     \u001b[39msuper\u001b[39m(MSSPM, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n",
      "\u001b[0;31mAssertionError\u001b[0m: Attention hidden dimension is not divisible by the number of attention heads"
     ]
    }
   ],
   "source": [
    "model = MSSPM(vocab_size, word_emb_dim, hidden_dim, event_size, num_heads)\n",
    "model.cuda()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-2)\n",
    "for e in range(num_epochs):\n",
    "    for i, (news, pos, stock, y, sent_lengths, stock_lengths) in enumerate(dataloader):\n",
    "        bsize = len(news)\n",
    "        for i in range(bsize):\n",
    "            if sent_lengths[i] == 0:\n",
    "                sent_lengths[i] += 1\n",
    "            elif stock_lengths[i] == 0:\n",
    "                stock_lengths[i] += 1\n",
    "        optimizer.zero_grad()\n",
    "        news = news.cuda()\n",
    "        pos = pos.cuda()\n",
    "        stock = stock.cuda()\n",
    "        y = y.cuda().view(-1, 1)\n",
    "        probs, loss_crf = model(news, pos, stock, sent_lengths, stock_lengths)\n",
    "        loss_bce = criterion(probs, y)\n",
    "        loss = eta * loss_bce + (1 - eta) * loss_crf\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    pretty_print(e, loss.item())     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
