{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in ./.venv/lib/python3.9/site-packages (1.26.4)\n",
      "^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0mRequirement already satisfied: pandas in ./.venv/lib/python3.9/site-packages (2.2.0)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in ./.venv/lib/python3.9/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.9/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.9/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: torch in ./.venv/lib/python3.9/site-packages (1.12.1)\n",
      "Requirement already satisfied: typing-extensions in ./.venv/lib/python3.9/site-packages (from torch) (4.5.0)\n"
     ]
    }
   ],
   "source": [
    "! pip3 install numpy\n",
    "! pip3 install pandas\n",
    "! pip3 install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in ./.venv/lib/python3.9/site-packages (3.8.1)\n",
      "Requirement already satisfied: click in ./.venv/lib/python3.9/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in ./.venv/lib/python3.9/site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./.venv/lib/python3.9/site-packages (from nltk) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.9/site-packages (from nltk) (4.66.2)\n"
     ]
    }
   ],
   "source": [
    "! pip3 install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stanza in ./.venv/lib/python3.9/site-packages (1.7.0)\n",
      "Requirement already satisfied: emoji in ./.venv/lib/python3.9/site-packages (from stanza) (2.10.1)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.9/site-packages (from stanza) (1.26.4)\n",
      "Requirement already satisfied: protobuf>=3.15.0 in ./.venv/lib/python3.9/site-packages (from stanza) (3.20.3)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.9/site-packages (from stanza) (2.31.0)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.9/site-packages (from stanza) (3.2.1)\n",
      "Requirement already satisfied: toml in ./.venv/lib/python3.9/site-packages (from stanza) (0.10.2)\n",
      "Requirement already satisfied: torch>=1.3.0 in ./.venv/lib/python3.9/site-packages (from stanza) (1.12.1)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.9/site-packages (from stanza) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions in ./.venv/lib/python3.9/site-packages (from torch>=1.3.0->stanza) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.9/site-packages (from requests->stanza) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.9/site-packages (from requests->stanza) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.9/site-packages (from requests->stanza) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.9/site-packages (from requests->stanza) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "! pip3 install stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.9/site-packages (1.4.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.19.5 in ./.venv/lib/python3.9/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in ./.venv/lib/python3.9/site-packages (from scikit-learn) (1.12.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.9/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./.venv/lib/python3.9/site-packages (from scikit-learn) (3.2.0)\n"
     ]
    }
   ],
   "source": [
    "! pip3 install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydantic==1.10.8\n",
      "  Using cached pydantic-1.10.8-cp39-cp39-macosx_10_9_x86_64.whl.metadata (146 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in ./.venv/lib/python3.9/site-packages (from pydantic==1.10.8) (4.5.0)\n",
      "Using cached pydantic-1.10.8-cp39-cp39-macosx_10_9_x86_64.whl (2.9 MB)\n",
      "Installing collected packages: pydantic\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 1.8.2\n",
      "    Uninstalling pydantic-1.8.2:\n",
      "      Successfully uninstalled pydantic-1.8.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spacy 3.3.3 requires pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4, but you have pydantic 1.10.8 which is incompatible.\n",
      "thinc 8.0.17 requires pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4, but you have pydantic 1.10.8 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed pydantic-1.10.8\n"
     ]
    }
   ],
   "source": [
    "! pip3 install pydantic==1.10.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: allennlp in ./.venv/lib/python3.9/site-packages (2.10.1)\n",
      "Requirement already satisfied: torch<1.13.0,>=1.10.0 in ./.venv/lib/python3.9/site-packages (from allennlp) (1.12.1)\n",
      "Requirement already satisfied: torchvision<0.14.0,>=0.8.1 in ./.venv/lib/python3.9/site-packages (from allennlp) (0.13.1)\n",
      "Requirement already satisfied: cached-path<1.2.0,>=1.1.3 in ./.venv/lib/python3.9/site-packages (from allennlp) (1.1.6)\n",
      "Requirement already satisfied: fairscale==0.4.6 in ./.venv/lib/python3.9/site-packages (from allennlp) (0.4.6)\n",
      "Requirement already satisfied: nltk>=3.6.5 in ./.venv/lib/python3.9/site-packages (from allennlp) (3.8.1)\n",
      "Requirement already satisfied: spacy<3.4,>=2.1.0 in ./.venv/lib/python3.9/site-packages (from allennlp) (3.3.3)\n",
      "Requirement already satisfied: numpy>=1.21.4 in ./.venv/lib/python3.9/site-packages (from allennlp) (1.26.4)\n",
      "Requirement already satisfied: tensorboardX>=1.2 in ./.venv/lib/python3.9/site-packages (from allennlp) (2.6.2.2)\n",
      "Requirement already satisfied: requests>=2.28 in ./.venv/lib/python3.9/site-packages (from allennlp) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62 in ./.venv/lib/python3.9/site-packages (from allennlp) (4.66.2)\n",
      "Requirement already satisfied: h5py>=3.6.0 in ./.venv/lib/python3.9/site-packages (from allennlp) (3.10.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.1 in ./.venv/lib/python3.9/site-packages (from allennlp) (1.4.0)\n",
      "Requirement already satisfied: scipy>=1.7.3 in ./.venv/lib/python3.9/site-packages (from allennlp) (1.12.0)\n",
      "Requirement already satisfied: pytest>=6.2.5 in ./.venv/lib/python3.9/site-packages (from allennlp) (8.0.0)\n",
      "Requirement already satisfied: transformers<4.21,>=4.1 in ./.venv/lib/python3.9/site-packages (from allennlp) (4.20.1)\n",
      "Requirement already satisfied: sentencepiece>=0.1.96 in ./.venv/lib/python3.9/site-packages (from allennlp) (0.1.99)\n",
      "Requirement already satisfied: filelock<3.8,>=3.3 in ./.venv/lib/python3.9/site-packages (from allennlp) (3.7.1)\n",
      "Requirement already satisfied: lmdb>=1.2.1 in ./.venv/lib/python3.9/site-packages (from allennlp) (1.4.1)\n",
      "Requirement already satisfied: more-itertools>=8.12.0 in ./.venv/lib/python3.9/site-packages (from allennlp) (10.2.0)\n",
      "Requirement already satisfied: termcolor==1.1.0 in ./.venv/lib/python3.9/site-packages (from allennlp) (1.1.0)\n",
      "Requirement already satisfied: wandb<0.13.0,>=0.10.0 in ./.venv/lib/python3.9/site-packages (from allennlp) (0.12.21)\n",
      "Requirement already satisfied: huggingface-hub>=0.0.16 in ./.venv/lib/python3.9/site-packages (from allennlp) (0.10.1)\n",
      "Requirement already satisfied: dill>=0.3.4 in ./.venv/lib/python3.9/site-packages (from allennlp) (0.3.8)\n",
      "Requirement already satisfied: base58>=2.1.1 in ./.venv/lib/python3.9/site-packages (from allennlp) (2.1.1)\n",
      "Requirement already satisfied: sacremoses in ./.venv/lib/python3.9/site-packages (from allennlp) (0.1.1)\n",
      "Requirement already satisfied: typer>=0.4.1 in ./.venv/lib/python3.9/site-packages (from allennlp) (0.4.2)\n",
      "Requirement already satisfied: protobuf<4.0.0,>=3.12.0 in ./.venv/lib/python3.9/site-packages (from allennlp) (3.20.3)\n",
      "Requirement already satisfied: traitlets>5.1.1 in ./.venv/lib/python3.9/site-packages (from allennlp) (5.14.1)\n",
      "^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip3 install allennlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOT HERE 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h1/ckvqd8ys0w18r_lfpbms82l80000gn/T/ipykernel_9887/3810321052.py:3: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOT HERE 2\n",
      "GOT HERE 3\n",
      "GOT HERE 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tiberiuscolina/Desktop/ComputerStuff/School/nlpfinancial/finegrainedevents/src/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOT HERE 6\n",
      "GOT HERE 7\n",
      "GOT HERE 8\n",
      "GOT HERE 9\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(\"GOT HERE 1\")\n",
    "import pandas as pd\n",
    "print(\"GOT HERE 2\")\n",
    "import json\n",
    "print(\"GOT HERE 3\")\n",
    "import nltk\n",
    "print(\"GOT HERE 4\")\n",
    "from data_utils import BuildPOS\n",
    "print(\"GOT HERE 6\")\n",
    "import torch.utils.data as data \n",
    "print(\"GOT HERE 7\")\n",
    "import time\n",
    "print(\"GOT HERE 8\")\n",
    "import torch\n",
    "print(\"GOT HERE 9\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-15 20:48:02 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.7.0.json: 370kB [00:00, 19.3MB/s]                    \n",
      "2024-02-15 20:48:03 INFO: Loading these models for language: en (English):\n",
      "===============================\n",
      "| Processor | Package         |\n",
      "-------------------------------\n",
      "| tokenize  | combined        |\n",
      "| mwt       | combined        |\n",
      "| pos       | combined_charlm |\n",
      "===============================\n",
      "\n",
      "2024-02-15 20:48:03 INFO: Using device: cpu\n",
      "2024-02-15 20:48:03 INFO: Loading: tokenize\n",
      "2024-02-15 20:48:03 INFO: Loading: mwt\n",
      "2024-02-15 20:48:03 INFO: Loading: pos\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At LSTM constructor\n",
      "Started RNNBase constructor\n",
      "Finished taking variables from params\n",
      "Checked if dropout is between 0 and 1\n",
      "Made through checks\n",
      "Currently on layer 0\n",
      "Completed dealing with layers\n",
      "Parameters flattened\n",
      "Parameters reset\n",
      "LSTM constructor complete\n",
      "At LSTM constructor\n",
      "Started RNNBase constructor\n",
      "Finished taking variables from params\n",
      "Checked if dropout is between 0 and 1\n",
      "Made through checks\n",
      "Currently on layer 0\n",
      "Completed dealing with layers\n",
      "Parameters flattened\n",
      "Parameters reset\n",
      "LSTM constructor complete\n",
      "At LSTM constructor\n",
      "Started RNNBase constructor\n",
      "Finished taking variables from params\n",
      "Checked if dropout is between 0 and 1\n",
      "Made through checks\n",
      "Currently on layer 0\n",
      "Completed dealing with layers\n",
      "Parameters flattened\n",
      "Parameters reset\n",
      "LSTM constructor complete\n",
      "At LSTM constructor\n",
      "Started RNNBase constructor\n",
      "Finished taking variables from params\n",
      "Checked if dropout is between 0 and 1\n",
      "Made through checks\n",
      "Currently on layer 0\n",
      "Completed dealing with layers\n",
      "Parameters flattened\n",
      "Parameters reset\n",
      "LSTM constructor complete\n",
      "At LSTM constructor\n",
      "Started RNNBase constructor\n",
      "Finished taking variables from params\n",
      "Checked if dropout is between 0 and 1\n",
      "Made through checks\n",
      "Currently on layer 0\n",
      "Completed dealing with layers\n",
      "Parameters flattened\n",
      "Parameters reset\n",
      "LSTM constructor complete\n",
      "At LSTM constructor\n",
      "Started RNNBase constructor\n",
      "Finished taking variables from params\n",
      "Checked if dropout is between 0 and 1\n",
      "Made through checks\n",
      "Currently on layer 0\n",
      "Completed dealing with layers\n",
      "Parameters flattened\n",
      "Parameters reset\n",
      "LSTM constructor complete\n",
      "At LSTM constructor\n",
      "Started RNNBase constructor\n",
      "Finished taking variables from params\n",
      "Checked if dropout is between 0 and 1\n",
      "Made through checks\n",
      "Currently on layer 0\n",
      "Completed dealing with layers\n",
      "Parameters flattened\n",
      "Parameters reset\n",
      "LSTM constructor complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-15 20:48:04 INFO: Done loading processors!\n",
      "2024-02-15 20:48:04 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.7.0.json: 370kB [00:00, 9.59MB/s]                    \n",
      "2024-02-15 20:48:05 INFO: Loading these models for language: en (English):\n",
      "=================================\n",
      "| Processor | Package           |\n",
      "---------------------------------\n",
      "| tokenize  | combined          |\n",
      "| mwt       | combined          |\n",
      "| pos       | combined_charlm   |\n",
      "| lemma     | combined_nocharlm |\n",
      "| depparse  | combined_charlm   |\n",
      "=================================\n",
      "\n",
      "2024-02-15 20:48:05 INFO: Using device: cpu\n",
      "2024-02-15 20:48:05 INFO: Loading: tokenize\n",
      "2024-02-15 20:48:05 INFO: Loading: mwt\n",
      "2024-02-15 20:48:05 INFO: Loading: pos\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At LSTM constructor\n",
      "Started RNNBase constructor\n",
      "Finished taking variables from params\n",
      "Checked if dropout is between 0 and 1\n",
      "Made through checks\n",
      "Currently on layer 0\n",
      "Completed dealing with layers\n",
      "Parameters flattened\n",
      "Parameters reset\n",
      "LSTM constructor complete\n",
      "At LSTM constructor\n",
      "Started RNNBase constructor\n",
      "Finished taking variables from params\n",
      "Checked if dropout is between 0 and 1\n",
      "Made through checks\n",
      "Currently on layer 0\n",
      "Completed dealing with layers\n",
      "Parameters flattened\n",
      "Parameters reset\n",
      "LSTM constructor complete\n",
      "At LSTM constructor\n",
      "Started RNNBase constructor\n",
      "Finished taking variables from params\n",
      "Checked if dropout is between 0 and 1\n",
      "Made through checks\n",
      "Currently on layer 0\n",
      "Completed dealing with layers\n",
      "Parameters flattened\n",
      "Parameters reset\n",
      "LSTM constructor complete\n",
      "At LSTM constructor\n",
      "Started RNNBase constructor\n",
      "Finished taking variables from params\n",
      "Checked if dropout is between 0 and 1\n",
      "Made through checks\n",
      "Currently on layer 0\n",
      "Completed dealing with layers\n",
      "Parameters flattened\n",
      "Parameters reset\n",
      "LSTM constructor complete\n",
      "At LSTM constructor\n",
      "Started RNNBase constructor\n",
      "Finished taking variables from params\n",
      "Checked if dropout is between 0 and 1\n",
      "Made through checks\n",
      "Currently on layer 0\n",
      "Completed dealing with layers\n",
      "Parameters flattened\n",
      "Parameters reset\n",
      "LSTM constructor complete\n",
      "At LSTM constructor\n",
      "Started RNNBase constructor\n",
      "Finished taking variables from params\n",
      "Checked if dropout is between 0 and 1\n",
      "Made through checks\n",
      "Currently on layer 0\n",
      "Completed dealing with layers\n",
      "Parameters flattened\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-15 20:48:06 INFO: Loading: lemma\n",
      "2024-02-15 20:48:06 INFO: Loading: depparse\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters reset\n",
      "LSTM constructor complete\n",
      "At LSTM constructor\n",
      "Started RNNBase constructor\n",
      "Finished taking variables from params\n",
      "Checked if dropout is between 0 and 1\n",
      "Made through checks\n",
      "Currently on layer 0\n",
      "Completed dealing with layers\n",
      "Parameters flattened\n",
      "Parameters reset\n",
      "LSTM constructor complete\n",
      "At LSTM constructor\n",
      "Started RNNBase constructor\n",
      "Finished taking variables from params\n",
      "Checked if dropout is between 0 and 1\n",
      "Made through checks\n",
      "Currently on layer 0\n",
      "Completed dealing with layers\n",
      "Parameters flattened\n",
      "Parameters reset\n",
      "LSTM constructor complete\n",
      "At LSTM constructor\n",
      "Started RNNBase constructor\n",
      "Finished taking variables from params\n",
      "Checked if dropout is between 0 and 1\n",
      "Made through checks\n",
      "Currently on layer 0\n",
      "Completed dealing with layers\n",
      "Parameters flattened\n",
      "Parameters reset\n",
      "LSTM constructor complete\n",
      "At LSTM constructor\n",
      "Started RNNBase constructor\n",
      "Finished taking variables from params\n",
      "Checked if dropout is between 0 and 1\n",
      "Made through checks\n",
      "Currently on layer 0\n",
      "Completed dealing with layers\n",
      "Parameters flattened\n",
      "Parameters reset\n",
      "LSTM constructor complete\n",
      "At LSTM constructor\n",
      "Started RNNBase constructor\n",
      "Finished taking variables from params\n",
      "Checked if dropout is between 0 and 1\n",
      "Made through checks\n",
      "Currently on layer 0\n",
      "Completed dealing with layers\n",
      "Parameters flattened\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-15 20:48:06 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters reset\n",
      "LSTM constructor complete\n"
     ]
    }
   ],
   "source": [
    "from process_text import BuildVocab, TextToSentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print(epoch, loss):\n",
    "    print('Epoch {} completed with loss {:.4f}'.format(epoch + 1, loss * (0.9 ** epoch)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data.json') as f:\n",
    "    dataset = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary built in 0.9079 sec, with size: 6326\n"
     ]
    }
   ],
   "source": [
    "vocab = BuildVocab()\n",
    "start = time.time()\n",
    "for i in range(len(dataset)):\n",
    "    text = TextToSentences(dataset[i]['news'].lower())\n",
    "    vocab.addText(text)\n",
    "print('Vocabulary built in {:.4f} sec, with size: {}'.format(time.time() - start, vocab.n_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS built in 0.0005 sec, with size: 16\n"
     ]
    }
   ],
   "source": [
    "pos = BuildPOS()\n",
    "start = time.time()\n",
    "for i in range(len(dataset)):\n",
    "    p = dataset[i]['pos']\n",
    "    pos.addPOS(p)\n",
    "print('POS built in {:.4f} sec, with size: {}'.format(time.time() - start, pos.n_pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StockPredictionDataset(data.Dataset):\n",
    "    def __init__(self, dataset, vocab, pos):\n",
    "        self.data = dataset\n",
    "        self.vocab = vocab\n",
    "        self.pos = pos\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        news_, pos_, stock_ = self.data[i]['news'], self.data[i]['pos'], self.data[i]['stock']\n",
    "        news_ = torch.Tensor(self.process_sent(news_)).long()\n",
    "        pos_ = torch.Tensor(self.process_pos(news_, pos_)).long()\n",
    "        stock_ = np.array(stock_)\n",
    "        y = int(np.sum((stock_[-1,:6] - stock_[-2,:6])) > 0) if len(stock_) >= 2 else 1\n",
    "        stock_ = torch.Tensor(stock_)\n",
    "        return news_, pos_, stock_, y\n",
    "    \n",
    "    def process_sent(self, sent):\n",
    "        tokens = nltk.word_tokenize(sent.lower())\n",
    "        out = []\n",
    "        out.append(self.vocab.word2index['<SOS>'])\n",
    "        out.extend([self.vocab.word2index[token] for token in tokens if token in self.vocab.word2index])\n",
    "        out.append(self.vocab.word2index['<EOS>'])\n",
    "        return out\n",
    "    \n",
    "    def process_pos(self, sent, pos):\n",
    "        out = [self.pos.pos2index['<SOS>']]\n",
    "        out.extend([self.pos.pos2index[token] for token in pos])\n",
    "        if len(sent) <= (len(pos) + 1):\n",
    "            pos = pos[:len(sent) - 2] \n",
    "        out.extend([self.pos.pos2index[pos[-1]] for _ in range(len(sent) - len(pos) - 2) ])\n",
    "        out.append(self.pos.pos2index['<EOS>'])\n",
    "        return out\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(data):\n",
    "    def merge(sequences, is_token):\n",
    "        lengths = [len(seq) for seq in sequences]\n",
    "        if is_token:\n",
    "            padded_seqs = torch.zeros(len(sequences), max(lengths)).long()\n",
    "        else:\n",
    "            padded_seqs = torch.zeros(len(sequences), max(lengths), 120)\n",
    "        for i, seq in enumerate(sequences):\n",
    "            end = lengths[i]\n",
    "            if end == 0:\n",
    "                continue\n",
    "            padded_seqs[i,:end] = seq[:]\n",
    "        return padded_seqs, lengths\n",
    "              \n",
    "    news, pos, stock, y = [], [], [], []\n",
    "    for i, (news_i, pos_i, stock_i, y_i) in enumerate(data):\n",
    "        news.append(news_i)\n",
    "        pos.append(pos_i)\n",
    "        stock.append(stock_i)\n",
    "        y.append(y_i)\n",
    "    news.sort(key = lambda x: len(x), reverse=True)\n",
    "    pos.sort(key = lambda x: len(x), reverse=True)\n",
    "    stock.sort(key = lambda x: len(x), reverse=True)\n",
    "    news, news_lengths = merge(news, True)\n",
    "    pos, _ = merge(pos, True)\n",
    "    stock, stock_lengths = merge(stock, False)\n",
    "    y = torch.Tensor(y)\n",
    "    return news, pos, stock, y, news_lengths, stock_lengths\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = StockPredictionDataset(dataset, vocab, pos)\n",
    "dataloader = torch.utils.data.DataLoader(dataset = dataset, batch_size=64, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import MSSPM\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_emb_dim = 256\n",
    "hidden_dim = 256\n",
    "vocab_size = vocab.n_words\n",
    "event_size = pos.n_pos\n",
    "num_heads = 4\n",
    "num_epochs = 10\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = SSPM(vocab_size, word_emb_dim, hidden_dim, event_size, num_heads)\n",
    "# model.cuda()\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=1e-2)\n",
    "\n",
    "# for e in range(num_epochs):\n",
    "#     for i, (news, pos, stock, y, sent_lengths, stock_lengths) in enumerate(dataloader):\n",
    "#         bsize = len(news)\n",
    "#         for i in range(bsize):\n",
    "#             if sent_lengths[i] == 0:\n",
    "#                 sent_lengths[i] += 1\n",
    "#             elif stock_lengths[i] == 0:\n",
    "#                 stock_lengths[i] += 1\n",
    "#         optimizer.zero_grad()\n",
    "        \n",
    "#         \"\"\"\n",
    "#         news = news.cuda()\n",
    "#         pos = pos.cuda()\n",
    "#         stock = stock.cuda()\n",
    "#         y = y.cuda().view(-1, 1)\n",
    "#         probs = model(news, pos, stock, sent_lengths, stock_lengths)\n",
    "#         loss = criterion(probs, y)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#     pretty_print(e, loss.item())   \n",
    "#     \"\"\"   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_emb_dim = 256\n",
    "hidden_dim = 256\n",
    "vocab_size = vocab.n_words\n",
    "event_size = pos.n_pos\n",
    "num_heads = 4\n",
    "num_epochs = 10\n",
    "eta = 0.5\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "pos.n_pos\n",
    "\n",
    "(hidden_dim * 2) % num_heads == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IS THE CODE GETTING HERE\n",
      "IT SHOULD BE GETTING HERE TOO\n",
      "GOT HERE 2\n",
      "GOT HERE 3\n",
      "Value of dropout is 4\n",
      "Value of dropout is 0.2\n",
      "At LSTM constructor\n",
      "Started RNNBase constructor\n",
      "Finished taking variables from params\n",
      "Checked if dropout is between 0 and 1\n",
      "Made through checks\n",
      "Currently on layer 0\n",
      "Currently on layer 1\n",
      "Currently on layer 2\n",
      "Currently on layer 3\n",
      "Currently on layer 4\n",
      "Currently on layer 5\n",
      "Currently on layer 6\n",
      "Currently on layer 7\n",
      "Currently on layer 8\n",
      "Currently on layer 9\n",
      "Currently on layer 10\n",
      "Currently on layer 11\n",
      "Currently on layer 12\n",
      "Currently on layer 13\n",
      "Currently on layer 14\n",
      "Currently on layer 15\n",
      "Currently on layer 16\n",
      "Currently on layer 17\n",
      "Currently on layer 18\n",
      "Currently on layer 19\n",
      "Currently on layer 20\n",
      "Currently on layer 21\n",
      "Currently on layer 22\n",
      "Currently on layer 23\n",
      "Currently on layer 24\n",
      "Currently on layer 25\n",
      "Currently on layer 26\n",
      "Currently on layer 27\n",
      "Currently on layer 28\n",
      "Currently on layer 29\n",
      "Currently on layer 30\n",
      "Currently on layer 31\n",
      "Currently on layer 32\n",
      "Currently on layer 33\n",
      "Currently on layer 34\n",
      "Currently on layer 35\n",
      "Currently on layer 36\n",
      "Currently on layer 37\n",
      "Currently on layer 38\n",
      "Currently on layer 39\n",
      "Currently on layer 40\n",
      "Currently on layer 41\n",
      "Currently on layer 42\n",
      "Currently on layer 43\n",
      "Currently on layer 44\n",
      "Currently on layer 45\n",
      "Currently on layer 46\n",
      "Currently on layer 47\n",
      "Currently on layer 48\n",
      "Currently on layer 49\n",
      "Currently on layer 50\n",
      "Currently on layer 51\n",
      "Currently on layer 52\n",
      "Currently on layer 53\n",
      "Currently on layer 54\n",
      "Currently on layer 55\n",
      "Currently on layer 56\n",
      "Currently on layer 57\n",
      "Currently on layer 58\n",
      "Currently on layer 59\n",
      "Currently on layer 60\n",
      "Currently on layer 61\n",
      "Currently on layer 62\n",
      "Currently on layer 63\n",
      "Currently on layer 64\n",
      "Currently on layer 65\n",
      "Currently on layer 66\n",
      "Currently on layer 67\n",
      "Currently on layer 68\n",
      "Currently on layer 69\n",
      "Currently on layer 70\n",
      "Currently on layer 71\n",
      "Currently on layer 72\n",
      "Currently on layer 73\n",
      "Currently on layer 74\n",
      "Currently on layer 75\n",
      "Currently on layer 76\n",
      "Currently on layer 77\n",
      "Currently on layer 78\n",
      "Currently on layer 79\n",
      "Currently on layer 80\n",
      "Currently on layer 81\n",
      "Currently on layer 82\n",
      "Currently on layer 83\n",
      "Currently on layer 84\n",
      "Currently on layer 85\n",
      "Currently on layer 86\n",
      "Currently on layer 87\n",
      "Currently on layer 88\n",
      "Currently on layer 89\n",
      "Currently on layer 90\n",
      "Currently on layer 91\n",
      "Currently on layer 92\n",
      "Currently on layer 93\n",
      "Currently on layer 94\n",
      "Currently on layer 95\n",
      "Currently on layer 96\n",
      "Currently on layer 97\n",
      "Currently on layer 98\n",
      "Currently on layer 99\n",
      "Currently on layer 100\n",
      "Currently on layer 101\n",
      "Currently on layer 102\n",
      "Currently on layer 103\n",
      "Currently on layer 104\n",
      "Currently on layer 105\n",
      "Currently on layer 106\n",
      "Currently on layer 107\n",
      "Currently on layer 108\n",
      "Currently on layer 109\n",
      "Currently on layer 110\n",
      "Currently on layer 111\n",
      "Currently on layer 112\n",
      "Currently on layer 113\n",
      "Currently on layer 114\n",
      "Currently on layer 115\n",
      "Currently on layer 116\n",
      "Currently on layer 117\n",
      "Currently on layer 118\n",
      "Currently on layer 119\n",
      "Currently on layer 120\n",
      "Currently on layer 121\n",
      "Currently on layer 122\n",
      "Currently on layer 123\n",
      "Currently on layer 124\n",
      "Currently on layer 125\n",
      "Currently on layer 126\n",
      "Currently on layer 127\n",
      "Currently on layer 128\n",
      "Currently on layer 129\n",
      "Currently on layer 130\n",
      "Currently on layer 131\n",
      "Currently on layer 132\n",
      "Currently on layer 133\n",
      "Currently on layer 134\n",
      "Currently on layer 135\n",
      "Currently on layer 136\n",
      "Currently on layer 137\n",
      "Currently on layer 138\n",
      "Currently on layer 139\n",
      "Currently on layer 140\n",
      "Currently on layer 141\n",
      "Currently on layer 142\n",
      "Currently on layer 143\n",
      "Currently on layer 144\n",
      "Currently on layer 145\n",
      "Currently on layer 146\n",
      "Currently on layer 147\n",
      "Currently on layer 148\n",
      "Currently on layer 149\n",
      "Currently on layer 150\n",
      "Currently on layer 151\n",
      "Currently on layer 152\n",
      "Currently on layer 153\n",
      "Currently on layer 154\n",
      "Currently on layer 155\n",
      "Currently on layer 156\n",
      "Currently on layer 157\n",
      "Currently on layer 158\n",
      "Currently on layer 159\n",
      "Currently on layer 160\n",
      "Currently on layer 161\n",
      "Currently on layer 162\n",
      "Currently on layer 163\n",
      "Currently on layer 164\n",
      "Currently on layer 165\n",
      "Currently on layer 166\n",
      "Currently on layer 167\n",
      "Currently on layer 168\n",
      "Currently on layer 169\n",
      "Currently on layer 170\n",
      "Currently on layer 171\n",
      "Currently on layer 172\n",
      "Currently on layer 173\n",
      "Currently on layer 174\n",
      "Currently on layer 175\n",
      "Currently on layer 176\n",
      "Currently on layer 177\n",
      "Currently on layer 178\n",
      "Currently on layer 179\n",
      "Currently on layer 180\n",
      "Currently on layer 181\n",
      "Currently on layer 182\n",
      "Currently on layer 183\n",
      "Currently on layer 184\n",
      "Currently on layer 185\n",
      "Currently on layer 186\n",
      "Currently on layer 187\n",
      "Currently on layer 188\n",
      "Currently on layer 189\n",
      "Currently on layer 190\n",
      "Currently on layer 191\n",
      "Currently on layer 192\n",
      "Currently on layer 193\n",
      "Currently on layer 194\n",
      "Currently on layer 195\n",
      "Currently on layer 196\n",
      "Currently on layer 197\n",
      "Currently on layer 198\n",
      "Currently on layer 199\n",
      "Currently on layer 200\n",
      "Currently on layer 201\n",
      "Currently on layer 202\n",
      "Currently on layer 203\n",
      "Currently on layer 204\n",
      "Currently on layer 205\n",
      "Currently on layer 206\n",
      "Currently on layer 207\n",
      "Currently on layer 208\n",
      "Currently on layer 209\n",
      "Currently on layer 210\n",
      "Currently on layer 211\n",
      "Currently on layer 212\n",
      "Currently on layer 213\n",
      "Currently on layer 214\n",
      "Currently on layer 215\n",
      "Currently on layer 216\n",
      "Currently on layer 217\n",
      "Currently on layer 218\n",
      "Currently on layer 219\n",
      "Currently on layer 220\n",
      "Currently on layer 221\n",
      "Currently on layer 222\n",
      "Currently on layer 223\n",
      "Currently on layer 224\n",
      "Currently on layer 225\n",
      "Currently on layer 226\n",
      "Currently on layer 227\n",
      "Currently on layer 228\n",
      "Currently on layer 229\n",
      "Currently on layer 230\n",
      "Currently on layer 231\n",
      "Currently on layer 232\n",
      "Currently on layer 233\n",
      "Currently on layer 234\n",
      "Currently on layer 235\n",
      "Currently on layer 236\n",
      "Currently on layer 237\n",
      "Currently on layer 238\n",
      "Currently on layer 239\n",
      "Currently on layer 240\n",
      "Currently on layer 241\n",
      "Currently on layer 242\n",
      "Currently on layer 243\n",
      "Currently on layer 244\n",
      "Currently on layer 245\n",
      "Currently on layer 246\n",
      "Currently on layer 247\n",
      "Currently on layer 248\n",
      "Currently on layer 249\n",
      "Currently on layer 250\n",
      "Currently on layer 251\n",
      "Currently on layer 252\n",
      "Currently on layer 253\n",
      "Currently on layer 254\n",
      "Currently on layer 255\n",
      "Completed dealing with layers\n",
      "Parameters flattened\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model = MSSPM(vocab_size, word_emb_dim, hidden_dim, event_size, num_heads)\n",
    "print(\"GOT HERE 12\")\n",
    "model.cuda()\n",
    "print(\"GOT HERE 13\")\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-2)\n",
    "print(\"GOT HERE 14\")\n",
    "for e in range(num_epochs):\n",
    "    print(f\"GOT HERE 15.{e}\")\n",
    "    for i, (news, pos, stock, y, sent_lengths, stock_lengths) in enumerate(dataloader):\n",
    "        bsize = len(news)\n",
    "        for i in range(bsize):\n",
    "            if sent_lengths[i] == 0:\n",
    "                sent_lengths[i] += 1\n",
    "            elif stock_lengths[i] == 0:\n",
    "                stock_lengths[i] += 1\n",
    "        optimizer.zero_grad()\n",
    "        news = news.cuda()\n",
    "        pos = pos.cuda()\n",
    "        stock = stock.cuda()\n",
    "        y = y.cuda().view(-1, 1)\n",
    "        probs, loss_crf = model(news, pos, stock, sent_lengths, stock_lengths)\n",
    "        loss_bce = criterion(probs, y)\n",
    "        loss = eta * loss_bce + (1 - eta) * loss_crf\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    pretty_print(e, loss.item())     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
